{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e7a1ab8-2599-417d-9a65-25ef07f3a786",
   "metadata": {
    "id": "7e7a1ab8-2599-417d-9a65-25ef07f3a786"
   },
   "source": [
    "# Lab | Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8882fc-4815-4567-92fa-b4816358ba7d",
   "metadata": {
    "id": "ce8882fc-4815-4567-92fa-b4816358ba7d"
   },
   "source": [
    "Welcome to the IMDb Web Scraping Adventure Lab!\n",
    "\n",
    "**Objective**\n",
    "\n",
    "In this lab, we will embark on a mission to unearth valuable insights from the vast sea of data available on IMDb, one of the largest online databases of movie, TV, and celebrity information. As budding data scientists and business analysts, you have been tasked to scrape a specific subset of data from IMDb to assist film production companies in understanding the landscape of highly-rated movies in a defined time period. Your insights will potentially influence the making of the next netflix movie!\n",
    "\n",
    "**Background**\n",
    "\n",
    "In a world where data has become the new currency, businesses are leveraging big data to make informed decisions that drive success and profitability. The entertainment industry, being no exception, utilizes data analytics to comprehend market trends, audience preferences, and the performance of films based on various parameters such as director, genre, stars involved, etc. IMDb stands as a goldmine of such data, offering intricate details of almost every movie ever made.\n",
    "\n",
    "**Task**\n",
    "\n",
    "Your task is to create a Python script using `BeautifulSoup` and `pandas` to scrape IMDb movie data based on user ratings and release dates. This script should be able to filter movies with ratings above a certain threshold and within a specified date range.\n",
    "\n",
    "**Expected Outcome**\n",
    "\n",
    "- A function named `scrape_imdb` that takes four parameters: `title_type`,`user_rating`, `start_date`, and `end_date`.\n",
    "- The function should return a DataFrame with the following columns:\n",
    "  - **Movie Nr**: The number representing the movie’s position in the list.\n",
    "  - **Title**: The title of the movie.\n",
    "  - **Year**: The year the movie was released.\n",
    "  - **Rating**: The IMDb rating of the movie.\n",
    "  - **Runtime (min)**: The duration of the movie in minutes.\n",
    "  - **Genre**: The genre of the movie.\n",
    "  - **Description**: A brief description of the movie.\n",
    "  - **Director**: The director of the movie.\n",
    "  - **Stars**: The main stars of the movie.\n",
    "  - **Votes**: The number of votes the movie received.\n",
    "  - **Gross ($M)**: The gross earnings of the movie in millions of USD.\n",
    "\n",
    "You will execute this script to scrape data for movies with the Title Type `Feature Film` that have a user rating of `7.5 and above` and were released between `January 1, 1990, and December 31, 1992`.\n",
    "\n",
    "Remember to experiment with different title types, dates and ratings to ensure your code is versatile and can handle various searches effectively!\n",
    "\n",
    "**Resources**\n",
    "\n",
    "- [Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Pandas Documentation](https://pandas.pydata.org/pandas-docs/stable/index.html)\n",
    "- [IMDb Advanced Search](https://www.imdb.com/search/title/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3519921d-5890-445b-9a33-934ed8ee378c",
   "metadata": {
    "id": "3519921d-5890-445b-9a33-934ed8ee378c"
   },
   "source": [
    "**Hint**\n",
    "\n",
    "Your first mission is to familiarize yourself with the IMDb advanced search page. Head over to [IMDb advanced search](https://www.imdb.com/search/title/) and input the following parameters, keeping all other fields to their default values or blank:\n",
    "\n",
    "- **Title Type**: Feature film\n",
    "- **Release date**: From 1990 to 1992 (Note: You don't need to specify the day and month)\n",
    "- **User Rating**: 7.5 to -\n",
    "\n",
    "Upon searching, you'll land on a page showcasing a list of movies, each displaying vital details such as the title, release year, and crew information. Your task is to scrape this treasure trove of data.\n",
    "\n",
    "Carefully examine the resulting URL and construct your own URL to include all the necessary parameters for filtering the movies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a83a0d-a742-49f6-985e-e27887cbf922",
   "metadata": {
    "id": "25a83a0d-a742-49f6-985e-e27887cbf922"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Best of luck! Immerse yourself in the world of movies and may the data be with you!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b75cf0d-9afa-4eec-a9e2-befeac68b2a0",
   "metadata": {
    "id": "7b75cf0d-9afa-4eec-a9e2-befeac68b2a0"
   },
   "source": [
    "**Important note**:\n",
    "\n",
    "In the fast-changing online world, websites often get updates and make changes. When you try this lab, the IMDb website might be different from what we expect.\n",
    "\n",
    "If you run into problems because of these changes, like new rules or things that stop you from getting data, don't worry! Instead, get creative.\n",
    "\n",
    "You can choose another website that interests you and is good for scraping data. Websites like Wikipedia or The New York Times are good options. The main goal is still the same: get useful data and learn how to scrape it from a website that you find interesting. It's a chance to practice your web scraping skills and explore a source of information you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b5b13a2-cbdf-40a9-82ea-b84b3a3c711c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Title                     Date  \\\n",
      "0   Dilwale Dulhania Le Jayenge             22 mars 2023   \n",
      "1       Laisse parler ton coeur          14 octobre 2022   \n",
      "2                      Dil Se..          14 octobre 2022   \n",
      "3                          Fire          28 janvier 1998   \n",
      "4                        Bombay         14 novembre 2022   \n",
      "5        Bade Miyan chote Miyan  Date de sortie inconnue   \n",
      "6                       Deewana  Date de sortie inconnue   \n",
      "7                          Ishq  Date de sortie inconnue   \n",
      "8                        Mehndi  Date de sortie inconnue   \n",
      "9                         Sadak  Date de sortie inconnue   \n",
      "10                       Loafer  Date de sortie inconnue   \n",
      "11                        Namak  Date de sortie inconnue   \n",
      "12       Jhooth bole kauwa kate  Date de sortie inconnue   \n",
      "13                     Miss 420  Date de sortie inconnue   \n",
      "\n",
      "                                   Genre  Duration Country  \n",
      "0            Bollywood, Comédie, Musical  3h 09min     N/A  \n",
      "1   Bollywood, Comédie, Comédie musicale  2h 57min     N/A  \n",
      "2              Bollywood, Comédie, Drame  2h 43min     N/A  \n",
      "3              Bollywood, Drame, Romance  1h 48min     N/A  \n",
      "4              Bollywood, Drame, Musical  2h 21min     N/A  \n",
      "5                      Action, Bollywood  2h 05min     N/A  \n",
      "6                      Action, Bollywood  3h 05min     N/A  \n",
      "7   Bollywood, Comédie musicale, Romance  2h 41min     N/A  \n",
      "8                     Bollywood, Comédie  2h 36min     N/A  \n",
      "9              Bollywood, Drame, Romance       N/A     N/A  \n",
      "10                     Action, Bollywood  2h 17min     N/A  \n",
      "11                     Action, Bollywood  2h 45min     N/A  \n",
      "12                    Bollywood, Comédie  2h 25min     N/A  \n",
      "13                    Bollywood, Romance  2h 14min     N/A  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_allocine(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Erreur de connexion: \", response.status_code)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    containers = soup.find_all('div', class_='card entity-card entity-card-list cf')\n",
    "\n",
    "    movie_data = []\n",
    "\n",
    "    for container in containers:\n",
    "        title_tag = container.find('a', class_='meta-title-link')\n",
    "        title = title_tag.text.strip() if title_tag else 'N/A'\n",
    "\n",
    "        # Extraire les informations du bloc meta-body-item meta-body-info\n",
    "        info_block = container.find('div', class_='meta-body-item meta-body-info')\n",
    "        if info_block:\n",
    "            info_text = info_block.get_text(\" | \", strip=True)\n",
    "            info_parts = [part.strip() for part in info_text.split(\"|\")]\n",
    "\n",
    "            # Extraire la date\n",
    "            date = info_parts[0] if len(info_parts) > 0 else 'N/A'\n",
    "            \n",
    "            # Extraire la durée\n",
    "            duration = next((part for part in info_parts if 'min' in part), 'N/A')\n",
    "            \n",
    "            # Extraire les genres\n",
    "            genres = [part for part in info_parts if part not in [date, duration] and part]\n",
    "            genre = ', '.join(genres).replace(', ,,', ',').replace(', ,,', ',').strip() if genres else 'N/A'\n",
    "        else:\n",
    "            date = 'N/A'\n",
    "            duration = 'N/A'\n",
    "            genre = 'N/A'\n",
    "\n",
    "        # Ajouter les informations collectées à la liste\n",
    "        movie_data.append([title, date, genre, duration, 'N/A'])\n",
    "\n",
    "    # Créer un DataFrame à partir des données collectées\n",
    "    df = pd.DataFrame(movie_data, columns=['Title', 'Date', 'Genre', 'Duration', 'Country'])\n",
    "    return df\n",
    "\n",
    "# Utiliser l'URL fournie\n",
    "url = \"https://www.allocine.fr/films/genre-13047/decennie-1990/\"\n",
    "df = scrape_allocine(url)\n",
    "print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab1217a-df9d-4a2b-a32c-2c5f1eecd52a",
   "metadata": {
    "id": "9ab1217a-df9d-4a2b-a32c-2c5f1eecd52a"
   },
   "source": [
    "## BONUS\n",
    "\n",
    "The search results span multiple pages, housing a total of 631 movies in our example with each page displaying 50 movies at most. To scrape data seamlessly from all pages, you'll need to dive deep into the structure of the URLs generated with each \"Next\" click.\n",
    "\n",
    "Take a close look at the following URLs:\n",
    "- First page:\n",
    "  ```\n",
    "  https://www.imdb.com/search/title/?title_type=feature&release_date=1990-01-01,1992-12-31&user_rating=7.5,\n",
    "  ```\n",
    "- Second page:\n",
    "  ```\n",
    "  https://www.imdb.com/search/title/?title_type=feature&release_date=1990-01-01,1992-12-31&user_rating=7.5,&start=51&ref_=adv_nxt\n",
    "  ```\n",
    "- Third page:\n",
    "  ```\n",
    "  https://www.imdb.com/search/title/?title_type=feature&release_date=1990-01-01,1992-12-31&user_rating=7.5,&start=101&ref_=adv_nxt\n",
    "  ```\n",
    "\n",
    "You should notice a pattern. There is a `start` parameter incrementing by 50 with each page, paired with a constant `ref_` parameter holding the value \"adv_nxt\".\n",
    "\n",
    "Modify your script so it's capable of iterating over all available pages to fetch data on all the 631 movies (631 is the total number of movies in the proposed example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21ac4fc0-a12b-4a00-9266-2020166f0dea",
   "metadata": {
    "id": "21ac4fc0-a12b-4a00-9266-2020166f0dea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n",
      "Scraping page 4\n",
      "Scraping page 5\n",
      "Scraping page 6\n",
      "Scraping page 7\n",
      "Scraping page 8\n",
      "Scraping page 9\n",
      "Scraping page 10\n",
      "Scraping page 11\n",
      "Scraping page 12\n",
      "Scraping page 13\n",
      "                                            Title               Date  \\\n",
      "0                                          Devdas       2 avril 2003   \n",
      "1    La Trilogie d'Apu : La Complainte du sentier  30 septembre 2003   \n",
      "2           La Légende de Baahubali : 1ère Partie        8 juin 2016   \n",
      "3                     Dilwale Dulhania Le Jayenge       22 mars 2023   \n",
      "4                                      Veer-Zaara      26 avril 2006   \n",
      "..                                            ...                ...   \n",
      "190                        Jusqu'au bout du monde         1 mai 2024   \n",
      "191                                N’avoue jamais      24 avril 2024   \n",
      "192                             Un homme en fuite         8 mai 2024   \n",
      "193                                   Border Line         1 mai 2024   \n",
      "194                       Une affaire de principe         1 mai 2024   \n",
      "\n",
      "                                  Genre  Duration Country  \n",
      "0                      Bollywood, Drame  3h 05min     N/A  \n",
      "1                      Bollywood, Drame  2h 05min     N/A  \n",
      "2                 Bollywood, Historique  2h 17min     N/A  \n",
      "3           Bollywood, Comédie, Musical  3h 09min     N/A  \n",
      "4    Bollywood, Drame, Comédie musicale  3h 10min     N/A  \n",
      "..                                  ...       ...     ...  \n",
      "190             Drame, Romance, Western  2h 09min     N/A  \n",
      "191                             Comédie  1h 34min     N/A  \n",
      "192                            Policier  1h 46min     N/A  \n",
      "193                     Drame, Thriller  1h 17min     N/A  \n",
      "194                     Drame, Thriller  1h 35min     N/A  \n",
      "\n",
      "[195 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_allocine_page(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Erreur de connexion: \", response.status_code)\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    containers = soup.find_all('div', class_='card entity-card entity-card-list cf')\n",
    "\n",
    "    movie_data = []\n",
    "\n",
    "    for container in containers:\n",
    "        title_tag = container.find('a', class_='meta-title-link')\n",
    "        title = title_tag.text.strip() if title_tag else 'N/A'\n",
    "\n",
    "        # Extraire les informations du bloc meta-body-item meta-body-info\n",
    "        info_block = container.find('div', class_='meta-body-item meta-body-info')\n",
    "        if info_block:\n",
    "            info_text = info_block.get_text(\" | \", strip=True)\n",
    "            info_parts = [part.strip() for part in info_text.split(\"|\")]\n",
    "\n",
    "            # Extraire la date\n",
    "            date = info_parts[0] if len(info_parts) > 0 else 'N/A'\n",
    "            \n",
    "            # Extraire la durée\n",
    "            duration = next((part for part in info_parts if 'min' in part), 'N/A')\n",
    "            \n",
    "            # Extraire les genres\n",
    "            genres = [part for part in info_parts if part not in [date, duration] and part]\n",
    "            genre = ', '.join(genres).replace(', ,,', ',').replace(', ,,', ',').strip() if genres else 'N/A'\n",
    "        else:\n",
    "            date = 'N/A'\n",
    "            duration = 'N/A'\n",
    "            genre = 'N/A'\n",
    "\n",
    "        # Ajouter les informations collectées à la liste\n",
    "        movie_data.append([title, date, genre, duration, 'N/A'])\n",
    "\n",
    "    return movie_data\n",
    "\n",
    "def scrape_allocine_all_pages(base_url, total_movies, movies_per_page=50):\n",
    "    all_movie_data = []\n",
    "    for start in range(1, total_movies + 1, movies_per_page):\n",
    "        url = f\"{base_url}?page={start}\"\n",
    "        print(f\"Scraping page {start // movies_per_page + 1}\")\n",
    "        page_data = scrape_allocine_page(url)\n",
    "        all_movie_data.extend(page_data)\n",
    "    \n",
    "    return pd.DataFrame(all_movie_data, columns=['Title', 'Date', 'Genre', 'Duration', 'Country'])\n",
    "\n",
    "# Utiliser l'URL fournie pour la première page\n",
    "base_url = \"https://www.allocine.fr/films/genre-13047/\"\n",
    "total_movies = 631\n",
    "\n",
    "df = scrape_allocine_all_pages(base_url, total_movies)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3456775b-1b84-48ab-927d-cefbb16b140e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
