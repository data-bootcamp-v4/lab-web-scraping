{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e7a1ab8-2599-417d-9a65-25ef07f3a786",
   "metadata": {
    "id": "7e7a1ab8-2599-417d-9a65-25ef07f3a786"
   },
   "source": [
    "# Lab | Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8882fc-4815-4567-92fa-b4816358ba7d",
   "metadata": {
    "id": "ce8882fc-4815-4567-92fa-b4816358ba7d"
   },
   "source": [
    "Welcome to the \"Books to Scrape\" Web Scraping Adventure Lab!\n",
    "\n",
    "**Objective**\n",
    "\n",
    "In this lab, we will embark on a mission to unearth valuable insights from the data available on Books to Scrape, an online platform showcasing a wide variety of books. As data analyst, you have been tasked with scraping a specific subset of book data from Books to Scrape to assist publishing companies in understanding the landscape of highly-rated books across different genres. Your insights will help shape future book marketing strategies and publishing decisions.\n",
    "\n",
    "**Background**\n",
    "\n",
    "In a world where data has become the new currency, businesses are leveraging big data to make informed decisions that drive success and profitability. The publishing industry, much like others, utilizes data analytics to understand market trends, reader preferences, and the performance of books based on factors such as genre, author, and ratings. Books to Scrape serves as a rich source of such data, offering detailed information about a diverse range of books, making it an ideal platform for extracting insights to aid in informed decision-making within the literary world.\n",
    "\n",
    "**Task**\n",
    "\n",
    "Your task is to create a Python script using BeautifulSoup and pandas to scrape Books to Scrape book data, focusing on book ratings and genres. The script should be able to filter books with ratings above a certain threshold and in specific genres. Additionally, the script should structure the scraped data in a tabular format using pandas for further analysis.\n",
    "\n",
    "**Expected Outcome**\n",
    "\n",
    "A function named `scrape_books` that takes two parameters: `min_rating` and `max_price`. The function should scrape book data from the \"Books to Scrape\" website and return a `pandas` DataFrame with the following columns:\n",
    "\n",
    "**Expected Outcome**\n",
    "\n",
    "- A function named `scrape_books` that takes two parameters: `min_rating` and `max_price`.\n",
    "- The function should return a DataFrame with the following columns:\n",
    " \n",
    "  - **Title**: The title of the book.\n",
    "  - **Price (£)**: The price of the book in pounds.\n",
    "  - **Rating**: The rating of the book (1-5 stars).\n",
    "\n",
    "  \n",
    "You will execute this script to scrape data for books with a minimum rating of `4.0 and above` and a maximum price of `£20`. \n",
    "\n",
    "Remember to experiment with different ratings and prices to ensure your code is versatile and can handle various searches effectively!\n",
    "\n",
    "**Resources**\n",
    "\n",
    "- [Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Pandas Documentation](https://pandas.pydata.org/pandas-docs/stable/index.html)\n",
    "- [Books to Scrape](https://books.toscrape.com/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3519921d-5890-445b-9a33-934ed8ee378c",
   "metadata": {
    "id": "3519921d-5890-445b-9a33-934ed8ee378c"
   },
   "source": [
    "**Hint**\n",
    "\n",
    "Your first mission is to familiarize yourself with the **Books to Scrape** website. Navigate to [Books to Scrape](http://books.toscrape.com/) and explore the available books to understand their layout and structure. \n",
    "\n",
    "Next, think about how you can set parameters for your data extraction:\n",
    "\n",
    "- **Minimum Rating**: Focus on books with a rating of 4.0 and above.\n",
    "- **Maximum Price**: Filter for books priced up to £20.\n",
    "\n",
    "After reviewing the site, you can construct a plan for scraping relevant data. Pay attention to the details displayed for each book, including the title, price, rating, and availability. This will help you identify the correct HTML elements to target with your scraping script.\n",
    "\n",
    "Make sure to build your scraping URL and logic based on the patterns you observe in the HTML structure of the book listings!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a83a0d-a742-49f6-985e-e27887cbf922",
   "metadata": {
    "id": "25a83a0d-a742-49f6-985e-e27887cbf922"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Best of luck! Immerse yourself in the world of books, and may the data be with you!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b75cf0d-9afa-4eec-a9e2-befeac68b2a0",
   "metadata": {
    "id": "7b75cf0d-9afa-4eec-a9e2-befeac68b2a0"
   },
   "source": [
    "**Important Note**:\n",
    "\n",
    "In the fast-changing online world, websites often update and change their structures. When you try this lab, the **Books to Scrape** website might differ from what you expect.\n",
    "\n",
    "If you encounter issues due to these changes, like new rules or obstacles preventing data extraction, don’t worry! Get creative.\n",
    "\n",
    "You can choose another website that interests you and is suitable for scraping data. Options like Wikipedia, The New York Times, or even library databases are great alternatives. The main goal remains the same: extract useful data and enhance your web scraping skills while exploring a source of information you enjoy. This is your opportunity to practice and adapt to different web environments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11ef9b4-ffb1-42be-96a6-131f3bf77a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Importing the data on python & exploring the data\n",
    "\n",
    "#3 use vizualization technique to display interesting oberservation using descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d2e986ac-e209-40d6-ab0d-aeb02b4d3640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2b95ca85-f98a-484a-aa7f-4c1ca18627eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# URL of the webpage to scrape\n",
    "url ='https://books.toscrape.com'\n",
    "# Make a GET request to fetch the raw HTML content\n",
    "response = requests.get(url)\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eaf66fcc-d3d5-44cf-a070-245911c2d1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>\n",
       "    All products | Books to Scrape - Sandbox\n",
       "</title>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0a2dcec6-b05e-4cf7-900b-cf78c3da9980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1792c3-8374-4a6e-93a7-18b8ace2ec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('a').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6825f3d1-3ec6-44b8-8a21-f7361afa7372",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('p',class_ = 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb5d45b-b6d3-49f1-98fb-a46ba4a77183",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('p',class_ = 'story')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "c854cb5c-4cae-47fc-92fd-7e3e4554fb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['£51.77',\n",
       " '£53.74',\n",
       " '£50.10',\n",
       " '£47.82',\n",
       " '£54.23',\n",
       " '£22.65',\n",
       " '£33.34',\n",
       " '£17.93',\n",
       " '£22.60',\n",
       " '£52.15',\n",
       " '£13.99',\n",
       " '£20.66',\n",
       " '£17.46',\n",
       " '£52.29',\n",
       " '£35.02',\n",
       " '£57.25',\n",
       " '£23.88',\n",
       " '£37.59',\n",
       " '£51.33',\n",
       " '£45.17']"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 Do Calcul/create functions\n",
    "book_prices=[]\n",
    "for book in soup.find_all(class_=\"price_color\"):\n",
    "    book_prices.append(book.get_text(strip=True))\n",
    "\n",
    "book_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "03cc18bf-b73c-4710-b844-059646427d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[51,\n",
       " 53,\n",
       " 50,\n",
       " 47,\n",
       " 54,\n",
       " 22,\n",
       " 33,\n",
       " 17,\n",
       " 22,\n",
       " 52,\n",
       " 13,\n",
       " 20,\n",
       " 17,\n",
       " 52,\n",
       " 35,\n",
       " 57,\n",
       " 23,\n",
       " 37,\n",
       " 51,\n",
       " 45]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original list of book prices with strings\n",
    "book_prices = ['£51.77', '£53.74', '£50.10', '£47.82', '£54.23', '£22.65', '£33.34', \n",
    "               '£17.93', '£22.60', '£52.15', '£13.99', '£20.66', '£17.46', '£52.29', \n",
    "               '£35.02', '£57.25', '£23.88', '£37.59', '£51.33', '£45.17']\n",
    "\n",
    "# Convert to a list of floats by removing the currency symbol\n",
    "cleaned_prices = [float(price.replace('£', '')) for price in book_prices]\n",
    "\n",
    "# If you want a list of integers instead of floats\n",
    "# Use `int()` to convert each float to an integer\n",
    "# Example below rounds to the nearest integer:\n",
    "book_pricess = [int(float(price.replace('£', ''))) for price in book_prices]\n",
    "\n",
    "book_pricess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ab0dc07b-51f1-4e68-bc3a-76af75e7cf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A Light in the Attic',\n",
       " 'Tipping the Velvet',\n",
       " 'Soumission',\n",
       " 'Sharp Objects',\n",
       " 'Sapiens: A Brief History of Humankind',\n",
       " 'The Requiem Red',\n",
       " 'The Dirty Little Secrets of Getting Your Dream Job',\n",
       " 'The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull',\n",
       " 'The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics',\n",
       " 'The Black Maria',\n",
       " 'Starving Hearts (Triangular Trade Trilogy, #1)',\n",
       " \"Shakespeare's Sonnets\",\n",
       " 'Set Me Free',\n",
       " \"Scott Pilgrim's Precious Little Life (Scott Pilgrim #1)\",\n",
       " 'Rip it Up and Start Again',\n",
       " 'Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991',\n",
       " 'Olio',\n",
       " 'Mesaerion: The Best Science Fiction Stories 1800-1849',\n",
       " 'Libertarianism for Beginners',\n",
       " \"It's Only the Himalayas\"]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_titles=[]\n",
    "for book in soup.find_all('a', title=True):\n",
    "    book_titles.append(book.get('title'))\n",
    "\n",
    "book_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "97a36ff1-2b7a-4f6a-acff-5bc888a545cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'get'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[171], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/bs4/element.py:2433\u001b[0m, in \u001b[0;36mResultSet.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   2432\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   2434\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResultSet object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. You\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m key\n\u001b[1;32m   2435\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: ResultSet object has no attribute 'get'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "soup.find_all('a', title=True)[0].get('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "950b3982-1350-45e0-a7de-f6f7d0926b5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Three',\n",
       " 'One',\n",
       " 'One',\n",
       " 'Four',\n",
       " 'Five',\n",
       " 'One',\n",
       " 'Four',\n",
       " 'Three',\n",
       " 'Four',\n",
       " 'One',\n",
       " 'Two',\n",
       " 'Four',\n",
       " 'Five',\n",
       " 'Five',\n",
       " 'Five',\n",
       " 'Three',\n",
       " 'One',\n",
       " 'One',\n",
       " 'Two',\n",
       " 'Two']"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_ratings=[]\n",
    "for book in soup.find_all('p',class_=\"star-rating\"):\n",
    "    rating = book.get(\"class\")[1]\n",
    "    book_ratings.append(rating)\n",
    "\n",
    "book_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd32127b-c150-411d-9ff1-a0a818b76d69",
   "metadata": {},
   "source": [
    "A function named scrape_books that takes two parameters: min_rating and max_price.\n",
    "\n",
    "The function should return a DataFrame with the following columns:\n",
    "\n",
    "Title: The title of the book.\n",
    "Price (£): The price of the book in pounds.\n",
    "Rating: The rating of the book (1-5 stars).\n",
    "You will execute this script to scrape data for books with a minimum rating of 4.0 and above and a maximum price of £20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "03706100-445b-4502-9125-4d19975c4f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_rating (book_ratings):\n",
    "    for rating in book_ratings:\n",
    "        if book_ratings == Five:\n",
    "            return result\n",
    "        elif book_ratings == Four:\n",
    "            return result\n",
    "        else:\n",
    "            return nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dfbf67-a794-423c-adfd-568be1601bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_price (book_price):\n",
    "    for rating in book_price:\n",
    "        if book_price <=20\n",
    "        return result\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
